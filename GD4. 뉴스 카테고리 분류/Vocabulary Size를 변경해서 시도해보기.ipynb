{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Vocabulary Size를 변경해서 시도해보기.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOPjyB61XfP5O2Xy1rpUhfj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"Kqsr2IgGyZC9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648638920670,"user_tz":-540,"elapsed":474,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"69f7bdff-174e-456d-fb88-cfeca63b1c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n","3.2.2\n","0.11.2\n","1.21.5\n","1.3.5\n","1.0.2\n"]}],"source":["import tensorflow\n","import matplotlib\n","import seaborn\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","\n","print(tensorflow.__version__)\n","print(matplotlib.__version__)\n","print(seaborn.__version__)\n","print(np.__version__)\n","print(pd.__version__)\n","print(sklearn.__version__)"]},{"cell_type":"code","source":["from tensorflow.keras.datasets import reuters \n"],"metadata":{"id":"VqVNZmpBiM4U","executionInfo":{"status":"ok","timestamp":1648639744146,"user_tz":-540,"elapsed":335,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["사용할 모델 : 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅"],"metadata":{"id":"JCUy661Fl47V"}},{"cell_type":"markdown","source":["1. 모든 단어 사용"],"metadata":{"id":"NWzlro2Sl0pH"}},{"cell_type":"code","source":["# 모든 단어 사용 \n","(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"],"metadata":{"id":"VNeHZDm9iPcD","executionInfo":{"status":"ok","timestamp":1648641421969,"user_tz":-540,"elapsed":1096,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["print(\"훈련 샘플의 수 : {}\".format(len(x_train)))\n","print(\"테스트 샘플의 수 : {}\".format(len(x_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRIQwhvLp23t","executionInfo":{"status":"ok","timestamp":1648641425101,"user_tz":-540,"elapsed":350,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"f6922299-d811-4355-9b3f-d134700c0ee2"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 샘플의 수 : 8982\n","테스트 샘플의 수 : 2246\n"]}]},{"cell_type":"code","source":["# 데이터 전처리 \n","word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"],"metadata":{"id":"1iDunDW3oJDc","executionInfo":{"status":"ok","timestamp":1648641426604,"user_tz":-540,"elapsed":3,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["index_to_word = { index + 3 : word for word, index in word_index.items() }\n","print(index_to_word[4])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkP-4cMEoTDx","executionInfo":{"status":"ok","timestamp":1648641427638,"user_tz":-540,"elapsed":2,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"cc7bf518-7d7b-42b2-862a-44358fc4fce4"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["the\n"]}]},{"cell_type":"code","source":["for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n","\t\tindex_to_word[index]=token"],"metadata":{"id":"YiIhwLkDoWeq","executionInfo":{"status":"ok","timestamp":1648641429354,"user_tz":-540,"elapsed":1,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["print(' '.join([index_to_word[index] for index in x_train[0]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jm4ryCj-ow-N","executionInfo":{"status":"ok","timestamp":1648641430563,"user_tz":-540,"elapsed":3,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"adacc656-0dc6-4140-cacc-63dc14b89b23"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"]}]},{"cell_type":"code","source":["decoded = []\n","for i in range(len(x_train)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_train[i]])\n","\t\tdecoded.append(t)\n","\n","x_train = decoded\n","print(len(x_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lWjWVF-oWhE","executionInfo":{"status":"ok","timestamp":1648641432299,"user_tz":-540,"elapsed":495,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"0110a68a-d398-4e52-b7d5-3d5b279de392"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["8982\n"]}]},{"cell_type":"code","source":["decoded = []\n","\n","for i in range(len(x_test)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_test[i]])\n","\t\tdecoded.append(t)\n","\n","x_test = decoded\n","print(len(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTjXO67foWjG","executionInfo":{"status":"ok","timestamp":1648641433268,"user_tz":-540,"elapsed":2,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"0a60988a-2111-4541-cd90-18f53d6046cb"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["2246\n"]}]},{"cell_type":"code","source":["x_train[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_ju4s02rkv5","executionInfo":{"status":"ok","timestamp":1648641434701,"user_tz":-540,"elapsed":315,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"109438c9-f3e9-4ae0-f406-0c1862efc06b"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n"," \"<sos> generale de banque sa lt genb br and lt heller overseas corp of chicago have each taken 50 pct stakes in factoring company sa belgo factors generale de banque said in a statement it gave no financial details of the transaction sa belgo factors' turnover in 1986 was 17 5 billion belgian francs reuter 3\",\n"," '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in enron corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national intergroup inc of 11 8 mln and brae corp of 15 6 mln reuter 3',\n"," \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely delinquent borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in fmha's financial eligibility standards indicated as many as one half of fmha borrowers who received new loans from the agency in 1986 would be ineligible under the proposed system the agency has proposed evaluating applicants' credit using a variety of financial ratios instead of relying solely on cashflow ability senate agriculture committee chairman patrick leahy d vt slammed the proposed eligibility changes telling fmha administrator vance clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to administer its 70 billion dlr loan portfolio in a compassionate yet judicious manner crowley of gao congress' investigative arm said the proposed credit scoring system attempted to ensure that fmha would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n"," '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d kaltenbacher to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to kaltenbacher arranging the necessary financing it said he intends to ask other members of senior management to participate the company said kaltenbacher owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# 데이터 전처리 (DTM, TD-IDF 행렬)\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","\n","dtmvector = CountVectorizer()\n","x_train_dtm = dtmvector.fit_transform(x_train)\n","\n","print(x_train_dtm.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRyHhZoimQbO","executionInfo":{"status":"ok","timestamp":1648641437487,"user_tz":-540,"elapsed":1432,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"1ea8f85e-e5da-4148-9d88-d4a486fed150"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["(8982, 26506)\n"]}]},{"cell_type":"code","source":["tfidf_transformer = TfidfTransformer()\n","tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n","print(tfidfv.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eu9tydlOrtgo","executionInfo":{"status":"ok","timestamp":1648641438820,"user_tz":-540,"elapsed":2,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"9489ec17-bd7d-417f-d0c5-9d6bde22fe49"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["(8982, 26506)\n"]}]},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score #정확도 계산"],"metadata":{"id":"ubkG_tW4mJxW","executionInfo":{"status":"ok","timestamp":1648642032223,"user_tz":-540,"elapsed":268,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"kuXA2uUSsSnt","executionInfo":{"status":"ok","timestamp":1648641529327,"user_tz":-540,"elapsed":2,"user":{"displayName":"강민호","userId":"16036611585333282679"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n","tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aBq8QqewmA48","executionInfo":{"status":"ok","timestamp":1648641441928,"user_tz":-540,"elapsed":291,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"368782ed-d26f-46c5-c060-e3d4f806218f"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB()"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# 나이브 베이즈 분류기 \n","model = MultinomialNB()\n","model.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,model.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKYFg6N8sAh_","executionInfo":{"status":"ok","timestamp":1648641555384,"user_tz":-540,"elapsed":1025,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"262ab5a8-d60c-4630-8a0a-a5ec66e72b27"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        12\n","           1       0.79      0.21      0.33       105\n","           2       0.00      0.00      0.00        20\n","           3       0.72      0.92      0.81       813\n","           4       0.45      0.96      0.61       474\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        38\n","           9       0.00      0.00      0.00        25\n","          10       0.00      0.00      0.00        30\n","          11       0.80      0.29      0.42        83\n","          12       0.00      0.00      0.00        13\n","          13       0.00      0.00      0.00        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.75      0.18      0.29        99\n","          17       0.00      0.00      0.00        12\n","          18       0.00      0.00      0.00        20\n","          19       0.73      0.58      0.64       133\n","          20       0.00      0.00      0.00        70\n","          21       0.00      0.00      0.00        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       0.00      0.00      0.00        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.00      0.00      0.00         5\n","          34       0.00      0.00      0.00         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.60      2246\n","   macro avg       0.09      0.07      0.07      2246\n","weighted avg       0.50      0.60      0.50      2246\n","\n"]}]},{"cell_type":"code","source":["# CNB \n","\n","cb = ComplementNB()\n","cb.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,cb.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlZyfm8EsdXR","executionInfo":{"status":"ok","timestamp":1648641636668,"user_tz":-540,"elapsed":488,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"5c705513-5eab-4e5e-e6da-bd6c2f088724"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.50      0.63        12\n","           1       0.63      0.88      0.73       105\n","           2       0.91      0.50      0.65        20\n","           3       0.87      0.91      0.89       813\n","           4       0.75      0.93      0.83       474\n","           5       0.00      0.00      0.00         5\n","           6       0.92      0.86      0.89        14\n","           7       1.00      0.67      0.80         3\n","           8       0.43      0.08      0.13        38\n","           9       0.81      0.88      0.85        25\n","          10       0.96      0.73      0.83        30\n","          11       0.55      0.67      0.61        83\n","          12       0.00      0.00      0.00        13\n","          13       0.62      0.54      0.58        37\n","          14       0.00      0.00      0.00         2\n","          15       0.50      0.11      0.18         9\n","          16       0.67      0.77      0.71        99\n","          17       0.00      0.00      0.00        12\n","          18       0.65      0.55      0.59        20\n","          19       0.55      0.80      0.65       133\n","          20       0.89      0.23      0.36        70\n","          21       0.84      0.59      0.70        27\n","          22       0.00      0.00      0.00         7\n","          23       0.71      0.42      0.53        12\n","          24       0.50      0.11      0.17        19\n","          25       0.83      0.61      0.70        31\n","          26       1.00      0.88      0.93         8\n","          27       0.00      0.00      0.00         4\n","          28       0.33      0.10      0.15        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       1.00      0.31      0.47        13\n","          32       1.00      0.80      0.89        10\n","          33       1.00      0.80      0.89         5\n","          34       1.00      0.71      0.83         7\n","          35       1.00      0.17      0.29         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       1.00      0.33      0.50         3\n","          39       1.00      0.20      0.33         5\n","          40       0.00      0.00      0.00        10\n","          41       0.67      0.25      0.36         8\n","          42       1.00      0.33      0.50         3\n","          43       1.00      0.17      0.29         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.76      2246\n","   macro avg       0.62      0.42      0.46      2246\n","weighted avg       0.75      0.76      0.73      2246\n","\n"]}]},{"cell_type":"code","source":["# 로지스틱 회귀\n","\n","lr = LogisticRegression(C=10000, penalty='l2')\n","lr.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lr.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ne7cYb7bs0Px","executionInfo":{"status":"ok","timestamp":1648641742156,"user_tz":-540,"elapsed":47906,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"d1dc7f6a-c785-40bb-83a3-7fedcc86f820"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.67      0.76        12\n","           1       0.75      0.80      0.77       105\n","           2       0.70      0.70      0.70        20\n","           3       0.93      0.93      0.93       813\n","           4       0.81      0.87      0.84       474\n","           5       1.00      0.20      0.33         5\n","           6       0.93      1.00      0.97        14\n","           7       1.00      0.67      0.80         3\n","           8       0.68      0.71      0.69        38\n","           9       0.81      0.88      0.85        25\n","          10       0.93      0.87      0.90        30\n","          11       0.66      0.73      0.70        83\n","          12       0.57      0.31      0.40        13\n","          13       0.61      0.62      0.61        37\n","          14       0.67      1.00      0.80         2\n","          15       0.71      0.56      0.63         9\n","          16       0.71      0.77      0.74        99\n","          17       0.67      0.50      0.57        12\n","          18       0.76      0.65      0.70        20\n","          19       0.69      0.70      0.69       133\n","          20       0.60      0.49      0.54        70\n","          21       0.63      0.81      0.71        27\n","          22       0.00      0.00      0.00         7\n","          23       0.69      0.75      0.72        12\n","          24       0.62      0.53      0.57        19\n","          25       0.92      0.74      0.82        31\n","          26       1.00      0.88      0.93         8\n","          27       1.00      0.25      0.40         4\n","          28       0.75      0.30      0.43        10\n","          29       0.57      1.00      0.73         4\n","          30       0.89      0.67      0.76        12\n","          31       0.75      0.46      0.57        13\n","          32       1.00      0.80      0.89        10\n","          33       0.80      0.80      0.80         5\n","          34       1.00      0.29      0.44         7\n","          35       1.00      0.33      0.50         6\n","          36       0.42      0.45      0.43        11\n","          37       0.50      0.50      0.50         2\n","          38       0.50      0.33      0.40         3\n","          39       0.50      0.40      0.44         5\n","          40       1.00      0.30      0.46        10\n","          41       0.83      0.62      0.71         8\n","          42       1.00      1.00      1.00         3\n","          43       0.86      1.00      0.92         6\n","          44       0.67      0.80      0.73         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.81      2246\n","   macro avg       0.76      0.64      0.67      2246\n","weighted avg       0.81      0.81      0.81      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]}]},{"cell_type":"code","source":["# 서포트 벡터 머신 \n","lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n","lsvc.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lsvc.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QcQ9WVoCtFBz","executionInfo":{"status":"ok","timestamp":1648641800604,"user_tz":-540,"elapsed":40637,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"3bd8a6dd-1b40-43c5-bf18-860f335ebbff"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.73      0.67      0.70        12\n","           1       0.73      0.70      0.71       105\n","           2       0.64      0.70      0.67        20\n","           3       0.90      0.90      0.90       813\n","           4       0.79      0.83      0.81       474\n","           5       0.50      0.20      0.29         5\n","           6       0.87      0.93      0.90        14\n","           7       1.00      0.33      0.50         3\n","           8       0.54      0.66      0.60        38\n","           9       0.88      0.84      0.86        25\n","          10       0.96      0.80      0.87        30\n","          11       0.57      0.66      0.61        83\n","          12       0.44      0.31      0.36        13\n","          13       0.49      0.51      0.50        37\n","          14       0.33      0.50      0.40         2\n","          15       0.50      0.22      0.31         9\n","          16       0.65      0.68      0.66        99\n","          17       0.67      0.17      0.27        12\n","          18       0.76      0.65      0.70        20\n","          19       0.58      0.64      0.61       133\n","          20       0.52      0.49      0.50        70\n","          21       0.62      0.78      0.69        27\n","          22       0.00      0.00      0.00         7\n","          23       0.60      0.50      0.55        12\n","          24       0.61      0.58      0.59        19\n","          25       0.92      0.71      0.80        31\n","          26       1.00      0.88      0.93         8\n","          27       1.00      0.50      0.67         4\n","          28       0.50      0.40      0.44        10\n","          29       0.33      0.75      0.46         4\n","          30       0.57      0.33      0.42        12\n","          31       0.88      0.54      0.67        13\n","          32       1.00      0.80      0.89        10\n","          33       0.83      1.00      0.91         5\n","          34       0.50      0.57      0.53         7\n","          35       1.00      0.33      0.50         6\n","          36       0.44      0.36      0.40        11\n","          37       1.00      0.50      0.67         2\n","          38       0.50      0.33      0.40         3\n","          39       0.50      0.20      0.29         5\n","          40       0.33      0.20      0.25        10\n","          41       0.80      0.50      0.62         8\n","          42       0.50      0.67      0.57         3\n","          43       0.86      1.00      0.92         6\n","          44       1.00      0.80      0.89         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.77      2246\n","   macro avg       0.67      0.58      0.60      2246\n","weighted avg       0.77      0.77      0.76      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["# 결정 트리\n","tree = DecisionTreeClassifier(max_depth=10, random_state = 0)\n","tree.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,tree.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdn6WgbLtZO3","executionInfo":{"status":"ok","timestamp":1648641910692,"user_tz":-540,"elapsed":3720,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"8db4e4c7-d66f-4eba-e521-b84a7de7c80b"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        12\n","           1       0.69      0.43      0.53       105\n","           2       0.75      0.45      0.56        20\n","           3       0.94      0.85      0.89       813\n","           4       0.40      0.89      0.55       474\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        38\n","           9       1.00      0.16      0.28        25\n","          10       0.89      0.80      0.84        30\n","          11       0.58      0.60      0.59        83\n","          12       0.00      0.00      0.00        13\n","          13       0.00      0.00      0.00        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.61      0.83      0.70        99\n","          17       0.00      0.00      0.00        12\n","          18       0.00      0.00      0.00        20\n","          19       0.67      0.41      0.50       133\n","          20       0.83      0.07      0.13        70\n","          21       0.00      0.00      0.00        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.67      0.11      0.18        19\n","          25       0.60      0.19      0.29        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.50      0.10      0.17        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       1.00      0.80      0.89         5\n","          34       0.00      0.00      0.00         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.62      2246\n","   macro avg       0.22      0.15      0.15      2246\n","weighted avg       0.62      0.62      0.58      2246\n","\n"]}]},{"cell_type":"code","source":["# 랜덤 포레스트\n","forest = RandomForestClassifier(n_estimators = 5, random_state=0)\n","forest.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,forest.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qTmOdoDtxMp","executionInfo":{"status":"ok","timestamp":1648641947543,"user_tz":-540,"elapsed":5136,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"b9def659-0b0a-4c2f-e928-c4fde4621014"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.25      0.58      0.35        12\n","           1       0.35      0.60      0.44       105\n","           2       0.32      0.40      0.36        20\n","           3       0.82      0.89      0.85       813\n","           4       0.62      0.84      0.71       474\n","           5       0.00      0.00      0.00         5\n","           6       0.67      0.43      0.52        14\n","           7       0.50      0.33      0.40         3\n","           8       0.51      0.47      0.49        38\n","           9       1.00      0.28      0.44        25\n","          10       0.46      0.20      0.28        30\n","          11       0.56      0.64      0.60        83\n","          12       0.40      0.15      0.22        13\n","          13       0.33      0.16      0.22        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.59      0.46      0.52        99\n","          17       0.00      0.00      0.00        12\n","          18       0.44      0.20      0.28        20\n","          19       0.61      0.50      0.55       133\n","          20       0.51      0.33      0.40        70\n","          21       0.55      0.22      0.32        27\n","          22       0.00      0.00      0.00         7\n","          23       0.33      0.08      0.13        12\n","          24       0.33      0.05      0.09        19\n","          25       1.00      0.23      0.37        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       1.00      0.10      0.18        10\n","          33       1.00      0.40      0.57         5\n","          34       0.00      0.00      0.00         7\n","          35       1.00      0.17      0.29         6\n","          36       0.43      0.27      0.33        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       1.00      0.30      0.46        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.75      0.50      0.60         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.65      2246\n","   macro avg       0.40      0.25      0.28      2246\n","weighted avg       0.63      0.65      0.62      2246\n","\n"]}]},{"cell_type":"code","source":["# 그래디언트 부스팅 트리\n","grbt = GradientBoostingClassifier(random_state=0)\n","grbt.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,grbt.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gptwVyUtz3d","executionInfo":{"status":"ok","timestamp":1648643334993,"user_tz":-540,"elapsed":1291575,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"14f93ef0-3c61-49d1-c52b-97d8951d13bd"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.50      0.55        12\n","           1       0.81      0.71      0.76       105\n","           2       0.58      0.70      0.64        20\n","           3       0.87      0.91      0.89       813\n","           4       0.78      0.86      0.82       474\n","           5       1.00      0.20      0.33         5\n","           6       0.77      0.71      0.74        14\n","           7       1.00      0.33      0.50         3\n","           8       0.60      0.63      0.62        38\n","           9       0.91      0.80      0.85        25\n","          10       0.79      0.77      0.78        30\n","          11       0.61      0.65      0.63        83\n","          12       0.50      0.46      0.48        13\n","          13       0.48      0.32      0.39        37\n","          14       0.00      0.00      0.00         2\n","          15       0.25      0.11      0.15         9\n","          16       0.72      0.71      0.71        99\n","          17       0.83      0.42      0.56        12\n","          18       0.59      0.50      0.54        20\n","          19       0.71      0.64      0.67       133\n","          20       0.64      0.41      0.50        70\n","          21       0.61      0.63      0.62        27\n","          22       0.33      0.14      0.20         7\n","          23       0.62      0.67      0.64        12\n","          24       0.69      0.47      0.56        19\n","          25       0.83      0.65      0.73        31\n","          26       1.00      1.00      1.00         8\n","          27       0.33      0.50      0.40         4\n","          28       0.25      0.20      0.22        10\n","          29       0.43      0.75      0.55         4\n","          30       0.36      0.42      0.38        12\n","          31       0.50      0.54      0.52        13\n","          32       1.00      1.00      1.00        10\n","          33       0.83      1.00      0.91         5\n","          34       0.60      0.43      0.50         7\n","          35       0.33      0.17      0.22         6\n","          36       0.50      0.64      0.56        11\n","          37       0.50      1.00      0.67         2\n","          38       0.33      0.33      0.33         3\n","          39       0.33      0.20      0.25         5\n","          40       0.83      0.50      0.62        10\n","          41       0.62      0.62      0.62         8\n","          42       1.00      0.67      0.80         3\n","          43       0.43      0.50      0.46         6\n","          44       0.80      0.80      0.80         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.77      2246\n","   macro avg       0.62      0.57      0.57      2246\n","weighted avg       0.77      0.77      0.76      2246\n","\n"]}]},{"cell_type":"code","source":["#보팅 \n","\n","voting_classifier = VotingClassifier(estimators=[\n","         ('lr', LogisticRegression(C=10000, penalty='l2')),\n","        ('cb', ComplementNB()),\n","        ('grbt', GradientBoostingClassifier(random_state=0))\n","], voting='soft', n_jobs=-1)\n","voting_classifier.fit(tfidfv, y_train)\n","\n","\n","print(classification_report(y_test,voting_classifier.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzGunqIOuDCx","executionInfo":{"status":"ok","timestamp":1648644565546,"user_tz":-540,"elapsed":1230556,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"7d0c2b22-a68f-4d1a-d3b4-517579b30d0c"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.75      0.75      0.75        12\n","           1       0.80      0.77      0.79       105\n","           2       0.67      0.80      0.73        20\n","           3       0.93      0.94      0.93       813\n","           4       0.82      0.88      0.85       474\n","           5       1.00      0.20      0.33         5\n","           6       0.87      0.93      0.90        14\n","           7       1.00      0.33      0.50         3\n","           8       0.69      0.71      0.70        38\n","           9       0.80      0.80      0.80        25\n","          10       0.90      0.90      0.90        30\n","          11       0.67      0.71      0.69        83\n","          12       0.60      0.46      0.52        13\n","          13       0.69      0.65      0.67        37\n","          14       0.29      1.00      0.44         2\n","          15       0.40      0.22      0.29         9\n","          16       0.73      0.76      0.74        99\n","          17       0.75      0.50      0.60        12\n","          18       0.73      0.55      0.63        20\n","          19       0.71      0.71      0.71       133\n","          20       0.66      0.50      0.57        70\n","          21       0.63      0.81      0.71        27\n","          22       1.00      0.14      0.25         7\n","          23       0.62      0.67      0.64        12\n","          24       0.73      0.58      0.65        19\n","          25       0.92      0.77      0.84        31\n","          26       1.00      1.00      1.00         8\n","          27       0.67      0.50      0.57         4\n","          28       0.33      0.30      0.32        10\n","          29       0.50      1.00      0.67         4\n","          30       0.54      0.58      0.56        12\n","          31       0.82      0.69      0.75        13\n","          32       1.00      1.00      1.00        10\n","          33       0.83      1.00      0.91         5\n","          34       0.80      0.57      0.67         7\n","          35       1.00      0.33      0.50         6\n","          36       0.54      0.64      0.58        11\n","          37       0.50      0.50      0.50         2\n","          38       0.50      0.33      0.40         3\n","          39       0.25      0.20      0.22         5\n","          40       1.00      0.40      0.57        10\n","          41       0.80      0.50      0.62         8\n","          42       1.00      1.00      1.00         3\n","          43       0.83      0.83      0.83         6\n","          44       0.80      0.80      0.80         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.82      2246\n","   macro avg       0.73      0.66      0.66      2246\n","weighted avg       0.82      0.82      0.81      2246\n","\n"]}]},{"cell_type":"markdown","source":["2. 빈도수 상위 5000개의 단어만 사용"],"metadata":{"id":"iUuMCuRQxsep"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n","\n","print(\"훈련 샘플의 수 : {}\".format(len(x_train)))\n","print(\"테스트 샘플의 수 : {}\".format(len(x_test)))\n","\n","# 데이터 전처리 \n","\n","decoded = []\n","for i in range(len(x_train)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_train[i]])\n","\t\tdecoded.append(t)\n","\n","x_train = decoded\n","print(len(x_train))\n","\n","decoded = []\n","\n","for i in range(len(x_test)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_test[i]])\n","\t\tdecoded.append(t)\n","\n","x_test = decoded\n","print(len(x_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87jYe6Fmxv4q","executionInfo":{"status":"ok","timestamp":1648644609642,"user_tz":-540,"elapsed":2283,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"2dc4cd17-e9f9-4875-fad1-687ee83ae597"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 샘플의 수 : 8982\n","테스트 샘플의 수 : 2246\n","8982\n","2246\n"]}]},{"cell_type":"code","source":["x_train[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gWyp58EyI5z","executionInfo":{"status":"ok","timestamp":1648644631237,"user_tz":-540,"elapsed":317,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"687d4feb-8091-4701-f88f-a722885a820c"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n"," '<sos> generale de banque sa lt <unk> <unk> and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3',\n"," '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in <unk> corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national <unk> inc of 11 8 mln and <unk> corp of 15 6 mln reuter 3',\n"," \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian <unk> senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial <unk> standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed <unk> <unk> credit using a variety of financial <unk> instead of <unk> <unk> on <unk> ability senate agriculture committee chairman <unk> <unk> d <unk> <unk> the proposed <unk> changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the <unk> purpose away from being <unk> <unk> of last <unk> toward becoming a big city bank but clark <unk> the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner <unk> of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of <unk> their debt reuter 3\",\n"," '<sos> <unk> co said its board has received a proposal from chairman and chief executive officer philip d <unk> to acquire <unk> for 15 75 dlrs per share in cash <unk> said the acquisition bid is subject to <unk> arranging the necessary financing it said he intends to ask other members of senior management to participate the company said <unk> owns 30 pct of <unk> stock and other management members another 7 5 pct <unk> said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["dtmvector = CountVectorizer()\n","x_train_dtm = dtmvector.fit_transform(x_train)\n","\n","print(x_train_dtm.shape)\n","\n","tfidf_transformer = TfidfTransformer()\n","tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n","print(tfidfv.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7D9Fj7lyaVc","executionInfo":{"status":"ok","timestamp":1648644635201,"user_tz":-540,"elapsed":1121,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"4e777dc2-5919-4e23-f70d-3d9dd7e5b5a3"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["(8982, 4867)\n","(8982, 4867)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"2Vn-nenbzGNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n","tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"],"metadata":{"executionInfo":{"status":"ok","timestamp":1648644698172,"user_tz":-540,"elapsed":996,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"id":"MvmziFvn4aNa"},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["# 나이브 베이즈 분류기 \n","model = MultinomialNB()\n","model.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,model.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644699802,"user_tz":-540,"elapsed":283,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"ed796fba-bc9a-4471-ab37-375f2b20e560","id":"IDKc2MIy0wGG"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        12\n","           1       0.50      0.80      0.62       105\n","           2       0.00      0.00      0.00        20\n","           3       0.86      0.89      0.87       813\n","           4       0.59      0.95      0.73       474\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        38\n","           9       1.00      0.28      0.44        25\n","          10       0.00      0.00      0.00        30\n","          11       0.48      0.73      0.58        83\n","          12       0.00      0.00      0.00        13\n","          13       1.00      0.14      0.24        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.60      0.66      0.62        99\n","          17       0.00      0.00      0.00        12\n","          18       0.00      0.00      0.00        20\n","          19       0.51      0.81      0.63       133\n","          20       0.90      0.13      0.23        70\n","          21       0.00      0.00      0.00        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       1.00      0.06      0.12        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.00      0.00      0.00         5\n","          34       0.00      0.00      0.00         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.67      2246\n","   macro avg       0.16      0.12      0.11      2246\n","weighted avg       0.60      0.67      0.60      2246\n","\n"]}]},{"cell_type":"code","source":["# CNB \n","\n","cb = ComplementNB()\n","cb.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,cb.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644703778,"user_tz":-540,"elapsed":328,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"84798c93-d7cd-402a-d037-744e99ab19cf","id":"Z9zgSg3w0rcR"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.58      0.70        12\n","           1       0.63      0.86      0.73       105\n","           2       0.91      0.50      0.65        20\n","           3       0.91      0.89      0.90       813\n","           4       0.74      0.92      0.82       474\n","           5       0.00      0.00      0.00         5\n","           6       0.86      0.86      0.86        14\n","           7       1.00      0.67      0.80         3\n","           8       0.57      0.21      0.31        38\n","           9       0.82      0.92      0.87        25\n","          10       0.96      0.80      0.87        30\n","          11       0.54      0.76      0.63        83\n","          12       0.00      0.00      0.00        13\n","          13       0.69      0.59      0.64        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.67      0.79      0.72        99\n","          17       0.00      0.00      0.00        12\n","          18       0.55      0.60      0.57        20\n","          19       0.56      0.80      0.66       133\n","          20       0.79      0.33      0.46        70\n","          21       0.78      0.67      0.72        27\n","          22       0.00      0.00      0.00         7\n","          23       0.67      0.33      0.44        12\n","          24       0.67      0.11      0.18        19\n","          25       0.86      0.77      0.81        31\n","          26       0.88      0.88      0.88         8\n","          27       1.00      0.25      0.40         4\n","          28       0.33      0.20      0.25        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       1.00      0.15      0.27        13\n","          32       1.00      0.70      0.82        10\n","          33       1.00      0.80      0.89         5\n","          34       1.00      0.71      0.83         7\n","          35       1.00      0.17      0.29         6\n","          36       0.00      0.00      0.00        11\n","          37       1.00      0.50      0.67         2\n","          38       1.00      0.33      0.50         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.67      0.25      0.36         8\n","          42       1.00      0.33      0.50         3\n","          43       1.00      0.17      0.29         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.77      2246\n","   macro avg       0.63      0.44      0.48      2246\n","weighted avg       0.76      0.77      0.75      2246\n","\n"]}]},{"cell_type":"code","source":["# 로지스틱 회귀\n","\n","lr = LogisticRegression(C=10000, penalty='l2')\n","lr.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lr.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644724126,"user_tz":-540,"elapsed":18371,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"7bb6aafc-ee59-4f56-bd43-10ec62301dda","id":"ql7rfqflzb-Q"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.67      0.76        12\n","           1       0.77      0.80      0.79       105\n","           2       0.74      0.85      0.79        20\n","           3       0.91      0.93      0.92       813\n","           4       0.81      0.87      0.84       474\n","           5       0.00      0.00      0.00         5\n","           6       0.92      0.86      0.89        14\n","           7       1.00      0.67      0.80         3\n","           8       0.64      0.74      0.68        38\n","           9       0.81      0.88      0.85        25\n","          10       0.93      0.87      0.90        30\n","          11       0.64      0.73      0.68        83\n","          12       0.57      0.31      0.40        13\n","          13       0.64      0.62      0.63        37\n","          14       0.50      0.50      0.50         2\n","          15       0.83      0.56      0.67         9\n","          16       0.67      0.73      0.70        99\n","          17       0.82      0.75      0.78        12\n","          18       0.80      0.60      0.69        20\n","          19       0.66      0.68      0.67       133\n","          20       0.61      0.47      0.53        70\n","          21       0.62      0.78      0.69        27\n","          22       0.00      0.00      0.00         7\n","          23       0.55      0.50      0.52        12\n","          24       0.69      0.58      0.63        19\n","          25       0.91      0.65      0.75        31\n","          26       1.00      0.88      0.93         8\n","          27       1.00      0.25      0.40         4\n","          28       0.67      0.40      0.50        10\n","          29       0.50      0.75      0.60         4\n","          30       1.00      0.42      0.59        12\n","          31       0.70      0.54      0.61        13\n","          32       1.00      0.80      0.89        10\n","          33       0.80      0.80      0.80         5\n","          34       1.00      0.29      0.44         7\n","          35       1.00      0.33      0.50         6\n","          36       0.38      0.27      0.32        11\n","          37       0.50      0.50      0.50         2\n","          38       0.50      0.33      0.40         3\n","          39       0.40      0.40      0.40         5\n","          40       0.75      0.30      0.43        10\n","          41       0.83      0.62      0.71         8\n","          42       1.00      0.67      0.80         3\n","          43       0.67      1.00      0.80         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.81      2246\n","   macro avg       0.73      0.61      0.64      2246\n","weighted avg       0.80      0.81      0.80      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]}]},{"cell_type":"code","source":["# 서포트 벡터 머신 \n","lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n","lsvc.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lsvc.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644765400,"user_tz":-540,"elapsed":41276,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"32ecf14e-5153-4faf-a21a-791b7513416b","id":"jL7ftl_qzXQ6"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      0.67      0.73        12\n","           1       0.70      0.70      0.70       105\n","           2       0.67      0.70      0.68        20\n","           3       0.89      0.90      0.90       813\n","           4       0.80      0.84      0.82       474\n","           5       0.00      0.00      0.00         5\n","           6       0.86      0.86      0.86        14\n","           7       0.50      0.33      0.40         3\n","           8       0.73      0.71      0.72        38\n","           9       0.80      0.80      0.80        25\n","          10       0.92      0.80      0.86        30\n","          11       0.64      0.75      0.69        83\n","          12       0.18      0.23      0.20        13\n","          13       0.55      0.62      0.58        37\n","          14       1.00      0.50      0.67         2\n","          15       0.50      0.11      0.18         9\n","          16       0.61      0.68      0.64        99\n","          17       1.00      0.33      0.50        12\n","          18       0.76      0.65      0.70        20\n","          19       0.63      0.63      0.63       133\n","          20       0.56      0.47      0.51        70\n","          21       0.59      0.74      0.66        27\n","          22       0.00      0.00      0.00         7\n","          23       0.57      0.67      0.62        12\n","          24       0.56      0.47      0.51        19\n","          25       0.86      0.58      0.69        31\n","          26       0.78      0.88      0.82         8\n","          27       1.00      0.50      0.67         4\n","          28       0.50      0.20      0.29        10\n","          29       0.33      0.75      0.46         4\n","          30       0.80      0.33      0.47        12\n","          31       0.46      0.46      0.46        13\n","          32       0.89      0.80      0.84        10\n","          33       0.80      0.80      0.80         5\n","          34       0.67      0.57      0.62         7\n","          35       1.00      0.33      0.50         6\n","          36       0.50      0.36      0.42        11\n","          37       0.67      1.00      0.80         2\n","          38       0.50      0.33      0.40         3\n","          39       0.50      0.20      0.29         5\n","          40       0.50      0.30      0.37        10\n","          41       0.44      0.50      0.47         8\n","          42       0.40      0.67      0.50         3\n","          43       0.75      1.00      0.86         6\n","          44       1.00      0.80      0.89         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.77      2246\n","   macro avg       0.64      0.58      0.58      2246\n","weighted avg       0.77      0.77      0.76      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["# 결정 트리\n","tree = DecisionTreeClassifier(max_depth=10, random_state = 0)\n","tree.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,tree.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644766251,"user_tz":-540,"elapsed":855,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"13d844af-9fee-440e-9c0a-e24394e706f5","id":"sY-RK5H1zMgD"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        12\n","           1       0.72      0.40      0.52       105\n","           2       0.60      0.45      0.51        20\n","           3       0.94      0.84      0.89       813\n","           4       0.39      0.91      0.55       474\n","           5       0.00      0.00      0.00         5\n","           6       1.00      0.57      0.73        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        38\n","           9       0.88      0.88      0.88        25\n","          10       0.87      0.87      0.87        30\n","          11       0.62      0.48      0.54        83\n","          12       0.17      0.08      0.11        13\n","          13       0.00      0.00      0.00        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.60      0.82      0.69        99\n","          17       0.00      0.00      0.00        12\n","          18       0.00      0.00      0.00        20\n","          19       0.62      0.26      0.37       133\n","          20       0.33      0.03      0.05        70\n","          21       0.00      0.00      0.00        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       1.00      0.05      0.10        19\n","          25       0.86      0.19      0.32        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.50      0.10      0.17        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.83      1.00      0.91         5\n","          34       0.00      0.00      0.00         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.62      2246\n","   macro avg       0.24      0.17      0.18      2246\n","weighted avg       0.61      0.62      0.57      2246\n","\n"]}]},{"cell_type":"code","source":["# 랜덤 포레스트\n","forest = RandomForestClassifier(n_estimators = 5, random_state=0)\n","forest.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,forest.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648644768543,"user_tz":-540,"elapsed":2294,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"8440bf9f-ae52-4a94-9ae6-6bc1008fcf46","id":"X8QGUbHrzUOp"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.28      0.42      0.33        12\n","           1       0.42      0.78      0.55       105\n","           2       0.44      0.35      0.39        20\n","           3       0.84      0.90      0.87       813\n","           4       0.68      0.84      0.75       474\n","           5       0.00      0.00      0.00         5\n","           6       0.86      0.43      0.57        14\n","           7       1.00      0.33      0.50         3\n","           8       0.59      0.53      0.56        38\n","           9       0.71      0.40      0.51        25\n","          10       0.89      0.53      0.67        30\n","          11       0.57      0.69      0.62        83\n","          12       0.33      0.15      0.21        13\n","          13       0.46      0.32      0.38        37\n","          14       0.00      0.00      0.00         2\n","          15       1.00      0.11      0.20         9\n","          16       0.70      0.67      0.68        99\n","          17       0.00      0.00      0.00        12\n","          18       0.60      0.45      0.51        20\n","          19       0.62      0.64      0.63       133\n","          20       0.46      0.33      0.38        70\n","          21       0.65      0.41      0.50        27\n","          22       0.00      0.00      0.00         7\n","          23       0.75      0.25      0.38        12\n","          24       0.33      0.05      0.09        19\n","          25       0.87      0.42      0.57        31\n","          26       1.00      0.12      0.22         8\n","          27       1.00      0.25      0.40         4\n","          28       0.00      0.00      0.00        10\n","          29       0.33      0.25      0.29         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       1.00      0.30      0.46        10\n","          33       1.00      0.20      0.33         5\n","          34       0.00      0.00      0.00         7\n","          35       1.00      0.17      0.29         6\n","          36       0.33      0.09      0.14        11\n","          37       1.00      0.50      0.67         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       1.00      0.20      0.33        10\n","          41       0.25      0.12      0.17         8\n","          42       0.00      0.00      0.00         3\n","          43       1.00      0.33      0.50         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.70      2246\n","   macro avg       0.54      0.31      0.36      2246\n","weighted avg       0.69      0.70      0.68      2246\n","\n"]}]},{"cell_type":"code","source":["# 그래디언트 부스팅 트리\n","grbt = GradientBoostingClassifier(random_state=0)\n","grbt.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,grbt.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648645815077,"user_tz":-540,"elapsed":1046539,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"8367bead-cafd-4f48-f996-8798983c8d37","id":"jCvWU7CDzRgw"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.67      0.76        12\n","           1       0.80      0.68      0.73       105\n","           2       0.70      0.70      0.70        20\n","           3       0.90      0.90      0.90       813\n","           4       0.76      0.83      0.79       474\n","           5       0.14      0.20      0.17         5\n","           6       0.93      0.93      0.93        14\n","           7       0.50      0.33      0.40         3\n","           8       0.64      0.66      0.65        38\n","           9       0.91      0.84      0.87        25\n","          10       0.87      0.87      0.87        30\n","          11       0.62      0.66      0.64        83\n","          12       0.46      0.46      0.46        13\n","          13       0.55      0.43      0.48        37\n","          14       0.08      0.50      0.14         2\n","          15       0.33      0.22      0.27         9\n","          16       0.72      0.77      0.75        99\n","          17       0.33      0.33      0.33        12\n","          18       0.61      0.55      0.58        20\n","          19       0.71      0.65      0.68       133\n","          20       0.56      0.44      0.50        70\n","          21       0.67      0.67      0.67        27\n","          22       0.50      0.14      0.22         7\n","          23       0.36      0.42      0.38        12\n","          24       0.71      0.63      0.67        19\n","          25       0.91      0.65      0.75        31\n","          26       0.75      0.75      0.75         8\n","          27       0.40      0.50      0.44         4\n","          28       0.38      0.30      0.33        10\n","          29       0.22      0.50      0.31         4\n","          30       0.38      0.42      0.40        12\n","          31       0.60      0.46      0.52        13\n","          32       0.88      0.70      0.78        10\n","          33       0.71      1.00      0.83         5\n","          34       0.50      0.29      0.36         7\n","          35       1.00      0.50      0.67         6\n","          36       0.67      0.55      0.60        11\n","          37       0.67      1.00      0.80         2\n","          38       0.25      0.33      0.29         3\n","          39       0.25      0.20      0.22         5\n","          40       0.71      0.50      0.59        10\n","          41       0.44      0.50      0.47         8\n","          42       0.75      1.00      0.86         3\n","          43       0.50      0.67      0.57         6\n","          44       1.00      0.80      0.89         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.77      2246\n","   macro avg       0.60      0.59      0.58      2246\n","weighted avg       0.77      0.77      0.77      2246\n","\n"]}]},{"cell_type":"code","source":["#보팅 \n","\n","voting_classifier = VotingClassifier(estimators=[\n","         ('lr', LogisticRegression(C=10000, penalty='l2')),\n","        ('cb', ComplementNB()),\n","        ('grbt', GradientBoostingClassifier(random_state=0))\n","], voting='soft', n_jobs=-1)\n","voting_classifier.fit(tfidfv, y_train)\n","\n","\n","print(classification_report(y_test,voting_classifier.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enIaqKRwzPGC","executionInfo":{"status":"ok","timestamp":1648646890842,"user_tz":-540,"elapsed":1075767,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"03115c8a-b688-46cc-b897-ce49a0d25d4f"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.75      0.82        12\n","           1       0.80      0.77      0.79       105\n","           2       0.71      0.85      0.77        20\n","           3       0.92      0.94      0.93       813\n","           4       0.82      0.88      0.85       474\n","           5       0.33      0.20      0.25         5\n","           6       0.93      0.93      0.93        14\n","           7       0.67      0.67      0.67         3\n","           8       0.72      0.68      0.70        38\n","           9       0.81      0.84      0.82        25\n","          10       0.93      0.90      0.92        30\n","          11       0.67      0.70      0.68        83\n","          12       0.60      0.46      0.52        13\n","          13       0.68      0.62      0.65        37\n","          14       0.12      0.50      0.20         2\n","          15       0.67      0.44      0.53         9\n","          16       0.74      0.74      0.74        99\n","          17       0.57      0.67      0.62        12\n","          18       0.72      0.65      0.68        20\n","          19       0.73      0.68      0.71       133\n","          20       0.61      0.49      0.54        70\n","          21       0.66      0.78      0.71        27\n","          22       0.50      0.14      0.22         7\n","          23       0.57      0.67      0.62        12\n","          24       0.75      0.63      0.69        19\n","          25       0.96      0.74      0.84        31\n","          26       0.88      0.88      0.88         8\n","          27       0.67      0.50      0.57         4\n","          28       0.44      0.40      0.42        10\n","          29       0.50      0.75      0.60         4\n","          30       0.62      0.42      0.50        12\n","          31       0.75      0.69      0.72        13\n","          32       1.00      0.80      0.89        10\n","          33       0.71      1.00      0.83         5\n","          34       1.00      0.43      0.60         7\n","          35       1.00      0.50      0.67         6\n","          36       0.45      0.45      0.45        11\n","          37       0.67      1.00      0.80         2\n","          38       0.50      0.33      0.40         3\n","          39       0.25      0.20      0.22         5\n","          40       0.80      0.40      0.53        10\n","          41       0.67      0.50      0.57         8\n","          42       0.75      1.00      0.86         3\n","          43       0.71      0.83      0.77         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.82      2246\n","   macro avg       0.71      0.66      0.66      2246\n","weighted avg       0.82      0.82      0.81      2246\n","\n"]}]},{"cell_type":"markdown","source":["3. 직접 단어 개수를 설정해서 사용"],"metadata":{"id":"GfBglJN73WFF"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n","\n","print(\"훈련 샘플의 수 : {}\".format(len(x_train)))\n","print(\"테스트 샘플의 수 : {}\".format(len(x_test)))\n","\n","# 데이터 전처리 \n","\n","decoded = []\n","for i in range(len(x_train)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_train[i]])\n","\t\tdecoded.append(t)\n","\n","x_train = decoded\n","print(len(x_train))\n","\n","decoded = []\n","\n","for i in range(len(x_test)) :\n","\t\tt = ' '.join([index_to_word[index] for index in x_test[i]])\n","\t\tdecoded.append(t)\n","\n","x_test = decoded\n","print(len(x_test))\n","\n","dtmvector = CountVectorizer()\n","x_train_dtm = dtmvector.fit_transform(x_train)\n","\n","print(x_train_dtm.shape)\n","\n","tfidf_transformer = TfidfTransformer()\n","tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n","print(tfidfv.shape)\n","\n","x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n","tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvvM_zKb3ZG_","executionInfo":{"status":"ok","timestamp":1648646893170,"user_tz":-540,"elapsed":2332,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"379c97fd-950a-46b4-a3f8-33ad3fceb823"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 샘플의 수 : 8982\n","테스트 샘플의 수 : 2246\n","8982\n","2246\n","(8982, 969)\n","(8982, 969)\n"]}]},{"cell_type":"code","source":["# 나이브 베이즈 분류기 \n","model = MultinomialNB()\n","model.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,model.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646893170,"user_tz":-540,"elapsed":6,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"c9a2e592-a3db-4cdb-b032-39a421b95a31","id":"S1Ph29M95Roe"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.25      0.40        12\n","           1       0.46      0.76      0.58       105\n","           2       0.00      0.00      0.00        20\n","           3       0.92      0.86      0.89       813\n","           4       0.60      0.95      0.73       474\n","           5       0.00      0.00      0.00         5\n","           6       0.00      0.00      0.00        14\n","           7       0.00      0.00      0.00         3\n","           8       0.78      0.37      0.50        38\n","           9       0.91      0.40      0.56        25\n","          10       1.00      0.20      0.33        30\n","          11       0.44      0.81      0.57        83\n","          12       0.00      0.00      0.00        13\n","          13       1.00      0.11      0.20        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.53      0.70      0.60        99\n","          17       0.00      0.00      0.00        12\n","          18       0.64      0.35      0.45        20\n","          19       0.54      0.77      0.64       133\n","          20       0.83      0.27      0.41        70\n","          21       1.00      0.41      0.58        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       0.00      0.00      0.00        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.00      0.00      0.00        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.00      0.00      0.00         5\n","          34       1.00      0.14      0.25         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.69      2246\n","   macro avg       0.25      0.16      0.17      2246\n","weighted avg       0.66      0.69      0.64      2246\n","\n"]}]},{"cell_type":"code","source":["# CNB \n","\n","cb = ComplementNB()\n","cb.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,cb.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646893711,"user_tz":-540,"elapsed":543,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"d79f654e-a603-491e-8868-7b440c84bb9a","id":"CbEu9Mla5Rol"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.55      0.50      0.52        12\n","           1       0.53      0.78      0.63       105\n","           2       0.00      0.00      0.00        20\n","           3       0.93      0.88      0.90       813\n","           4       0.69      0.93      0.79       474\n","           5       0.00      0.00      0.00         5\n","           6       0.82      0.64      0.72        14\n","           7       1.00      0.33      0.50         3\n","           8       0.69      0.24      0.35        38\n","           9       0.83      0.96      0.89        25\n","          10       0.88      0.73      0.80        30\n","          11       0.50      0.78      0.61        83\n","          12       0.00      0.00      0.00        13\n","          13       0.64      0.38      0.47        37\n","          14       1.00      0.50      0.67         2\n","          15       0.00      0.00      0.00         9\n","          16       0.60      0.75      0.67        99\n","          17       0.00      0.00      0.00        12\n","          18       0.46      0.60      0.52        20\n","          19       0.53      0.82      0.65       133\n","          20       0.81      0.30      0.44        70\n","          21       0.92      0.41      0.56        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.00      0.00      0.00        19\n","          25       0.75      0.58      0.65        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       1.00      0.10      0.18        10\n","          29       0.00      0.00      0.00         4\n","          30       1.00      0.08      0.15        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.00      0.00      0.00         5\n","          34       1.00      0.86      0.92         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.00      0.00      0.00        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       1.00      0.80      0.89         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.73      2246\n","   macro avg       0.37      0.28      0.29      2246\n","weighted avg       0.70      0.73      0.70      2246\n","\n"]}]},{"cell_type":"code","source":["# 로지스틱 회귀\n","\n","lr = LogisticRegression(C=10000, penalty='l2')\n","lr.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lr.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646906935,"user_tz":-540,"elapsed":13228,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"55d401e8-3fed-4127-a38e-6b1165cc86c6","id":"GqZxKnIZ5Rol"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.58      0.70        12\n","           1       0.74      0.75      0.75       105\n","           2       0.65      0.65      0.65        20\n","           3       0.90      0.93      0.91       813\n","           4       0.80      0.85      0.82       474\n","           5       1.00      0.20      0.33         5\n","           6       0.93      0.93      0.93        14\n","           7       1.00      0.33      0.50         3\n","           8       0.60      0.68      0.64        38\n","           9       0.80      0.80      0.80        25\n","          10       0.86      0.80      0.83        30\n","          11       0.64      0.69      0.66        83\n","          12       0.86      0.46      0.60        13\n","          13       0.50      0.62      0.55        37\n","          14       0.20      0.50      0.29         2\n","          15       0.80      0.44      0.57         9\n","          16       0.65      0.72      0.68        99\n","          17       0.64      0.75      0.69        12\n","          18       0.80      0.60      0.69        20\n","          19       0.69      0.62      0.66       133\n","          20       0.44      0.43      0.43        70\n","          21       0.61      0.81      0.70        27\n","          22       1.00      0.14      0.25         7\n","          23       0.22      0.17      0.19        12\n","          24       0.67      0.42      0.52        19\n","          25       0.92      0.71      0.80        31\n","          26       0.80      0.50      0.62         8\n","          27       1.00      0.25      0.40         4\n","          28       0.80      0.40      0.53        10\n","          29       0.40      1.00      0.57         4\n","          30       0.86      0.50      0.63        12\n","          31       0.56      0.38      0.45        13\n","          32       1.00      0.60      0.75        10\n","          33       0.80      0.80      0.80         5\n","          34       0.67      0.29      0.40         7\n","          35       1.00      0.50      0.67         6\n","          36       0.36      0.36      0.36        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.50      0.60      0.55         5\n","          40       0.40      0.20      0.27        10\n","          41       0.50      0.12      0.20         8\n","          42       0.00      0.00      0.00         3\n","          43       0.80      0.67      0.73         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.78      2246\n","   macro avg       0.68      0.53      0.56      2246\n","weighted avg       0.78      0.78      0.77      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]}]},{"cell_type":"code","source":["# 서포트 벡터 머신 \n","lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n","lsvc.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,lsvc.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646943322,"user_tz":-540,"elapsed":36393,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"9ec022fa-009d-4728-c3ad-df0790a469e5","id":"Deoste5t5Rom"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.67      0.76        12\n","           1       0.65      0.70      0.67       105\n","           2       0.39      0.45      0.42        20\n","           3       0.90      0.91      0.90       813\n","           4       0.75      0.79      0.77       474\n","           5       0.00      0.00      0.00         5\n","           6       0.81      0.93      0.87        14\n","           7       1.00      0.67      0.80         3\n","           8       0.57      0.66      0.61        38\n","           9       0.75      0.72      0.73        25\n","          10       0.84      0.70      0.76        30\n","          11       0.59      0.58      0.59        83\n","          12       0.45      0.38      0.42        13\n","          13       0.44      0.54      0.49        37\n","          14       0.50      0.50      0.50         2\n","          15       0.40      0.22      0.29         9\n","          16       0.62      0.62      0.62        99\n","          17       0.71      0.42      0.53        12\n","          18       0.75      0.45      0.56        20\n","          19       0.55      0.53      0.54       133\n","          20       0.38      0.39      0.38        70\n","          21       0.56      0.67      0.61        27\n","          22       0.00      0.00      0.00         7\n","          23       0.17      0.17      0.17        12\n","          24       0.42      0.26      0.32        19\n","          25       0.80      0.65      0.71        31\n","          26       1.00      0.62      0.77         8\n","          27       0.33      0.25      0.29         4\n","          28       0.33      0.20      0.25        10\n","          29       0.25      0.50      0.33         4\n","          30       0.43      0.25      0.32        12\n","          31       0.33      0.15      0.21        13\n","          32       0.60      0.60      0.60        10\n","          33       0.80      0.80      0.80         5\n","          34       0.50      0.57      0.53         7\n","          35       1.00      0.17      0.29         6\n","          36       0.20      0.18      0.19        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.18      0.40      0.25         5\n","          40       0.30      0.30      0.30        10\n","          41       0.17      0.12      0.14         8\n","          42       0.00      0.00      0.00         3\n","          43       0.33      0.67      0.44         6\n","          44       0.80      0.80      0.80         5\n","          45       0.50      1.00      0.67         1\n","\n","    accuracy                           0.72      2246\n","   macro avg       0.50      0.46      0.46      2246\n","weighted avg       0.72      0.72      0.72      2246\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["# 결정 트리\n","tree = DecisionTreeClassifier(max_depth=10, random_state = 0)\n","tree.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,tree.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646944455,"user_tz":-540,"elapsed":1146,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"f8957aa9-8b29-4d24-a427-ffa3427806df","id":"VIJDB2N_5Rom"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        12\n","           1       0.73      0.42      0.53       105\n","           2       0.67      0.30      0.41        20\n","           3       0.58      0.90      0.70       813\n","           4       0.69      0.81      0.75       474\n","           5       0.00      0.00      0.00         5\n","           6       1.00      0.64      0.78        14\n","           7       0.00      0.00      0.00         3\n","           8       0.00      0.00      0.00        38\n","           9       0.00      0.00      0.00        25\n","          10       0.93      0.87      0.90        30\n","          11       0.57      0.59      0.58        83\n","          12       0.00      0.00      0.00        13\n","          13       0.00      0.00      0.00        37\n","          14       0.00      0.00      0.00         2\n","          15       0.00      0.00      0.00         9\n","          16       0.57      0.76      0.65        99\n","          17       0.00      0.00      0.00        12\n","          18       0.00      0.00      0.00        20\n","          19       0.67      0.43      0.52       133\n","          20       0.67      0.03      0.05        70\n","          21       0.00      0.00      0.00        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.43      0.16      0.23        19\n","          25       0.50      0.03      0.06        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       0.50      0.10      0.17        10\n","          29       0.00      0.00      0.00         4\n","          30       0.00      0.00      0.00        12\n","          31       0.00      0.00      0.00        13\n","          32       0.00      0.00      0.00        10\n","          33       0.00      0.00      0.00         5\n","          34       0.00      0.00      0.00         7\n","          35       0.00      0.00      0.00         6\n","          36       0.00      0.00      0.00        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       1.00      0.10      0.18        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.00      0.00      0.00         6\n","          44       0.00      0.00      0.00         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.62      2246\n","   macro avg       0.21      0.13      0.14      2246\n","weighted avg       0.54      0.62      0.55      2246\n","\n"]}]},{"cell_type":"code","source":["# 랜덤 포레스트\n","forest = RandomForestClassifier(n_estimators = 5, random_state=0)\n","forest.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,forest.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648646945703,"user_tz":-540,"elapsed":1249,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"d514e3b9-4293-4c46-c49d-576d13602665","id":"7qPUddr75Rom"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.35      0.58      0.44        12\n","           1       0.47      0.79      0.59       105\n","           2       0.27      0.20      0.23        20\n","           3       0.85      0.91      0.88       813\n","           4       0.69      0.86      0.76       474\n","           5       0.00      0.00      0.00         5\n","           6       0.73      0.57      0.64        14\n","           7       0.20      0.33      0.25         3\n","           8       0.46      0.50      0.48        38\n","           9       0.82      0.72      0.77        25\n","          10       0.73      0.53      0.62        30\n","          11       0.62      0.63      0.62        83\n","          12       0.40      0.15      0.22        13\n","          13       0.48      0.35      0.41        37\n","          14       0.00      0.00      0.00         2\n","          15       0.50      0.11      0.18         9\n","          16       0.61      0.55      0.57        99\n","          17       1.00      0.08      0.15        12\n","          18       0.71      0.50      0.59        20\n","          19       0.57      0.58      0.58       133\n","          20       0.58      0.30      0.40        70\n","          21       0.74      0.52      0.61        27\n","          22       0.00      0.00      0.00         7\n","          23       0.25      0.08      0.12        12\n","          24       0.20      0.05      0.08        19\n","          25       1.00      0.52      0.68        31\n","          26       0.00      0.00      0.00         8\n","          27       0.00      0.00      0.00         4\n","          28       1.00      0.10      0.18        10\n","          29       0.50      0.50      0.50         4\n","          30       0.60      0.25      0.35        12\n","          31       0.00      0.00      0.00        13\n","          32       0.50      0.10      0.17        10\n","          33       1.00      0.40      0.57         5\n","          34       0.00      0.00      0.00         7\n","          35       0.50      0.17      0.25         6\n","          36       0.62      0.45      0.53        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       1.00      0.20      0.33        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       1.00      0.33      0.50         6\n","          44       1.00      0.80      0.89         5\n","          45       1.00      1.00      1.00         1\n","\n","    accuracy                           0.71      2246\n","   macro avg       0.48      0.32      0.35      2246\n","weighted avg       0.69      0.71      0.68      2246\n","\n"]}]},{"cell_type":"code","source":["# 그래디언트 부스팅 트리\n","grbt = GradientBoostingClassifier(random_state=0)\n","grbt.fit(tfidfv, y_train)\n","\n","print(classification_report(y_test,grbt.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXXdVBpf5Rom","executionInfo":{"status":"ok","timestamp":1648647812714,"user_tz":-540,"elapsed":853236,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"92b33b13-0a40-4da6-d044-6e52e02c4fb9"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.58      0.70        12\n","           1       0.75      0.66      0.70       105\n","           2       0.73      0.55      0.63        20\n","           3       0.89      0.91      0.90       813\n","           4       0.73      0.85      0.78       474\n","           5       0.20      0.20      0.20         5\n","           6       0.93      0.93      0.93        14\n","           7       0.25      0.33      0.29         3\n","           8       0.51      0.58      0.54        38\n","           9       0.79      0.76      0.78        25\n","          10       0.87      0.87      0.87        30\n","          11       0.65      0.67      0.66        83\n","          12       0.36      0.38      0.37        13\n","          13       0.51      0.51      0.51        37\n","          14       0.17      0.50      0.25         2\n","          15       0.40      0.22      0.29         9\n","          16       0.65      0.72      0.68        99\n","          17       0.50      0.58      0.54        12\n","          18       0.56      0.45      0.50        20\n","          19       0.71      0.68      0.70       133\n","          20       0.65      0.44      0.53        70\n","          21       0.61      0.63      0.62        27\n","          22       0.00      0.00      0.00         7\n","          23       0.00      0.00      0.00        12\n","          24       0.46      0.32      0.37        19\n","          25       0.90      0.58      0.71        31\n","          26       0.67      0.25      0.36         8\n","          27       0.25      0.25      0.25         4\n","          28       0.12      0.10      0.11        10\n","          29       0.14      0.25      0.18         4\n","          30       0.23      0.25      0.24        12\n","          31       0.33      0.31      0.32        13\n","          32       0.83      0.50      0.62        10\n","          33       0.40      0.40      0.40         5\n","          34       1.00      0.29      0.44         7\n","          35       0.50      0.17      0.25         6\n","          36       0.31      0.36      0.33        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.00      0.00      0.00         5\n","          40       0.67      0.20      0.31        10\n","          41       0.00      0.00      0.00         8\n","          42       0.00      0.00      0.00         3\n","          43       0.43      0.50      0.46         6\n","          44       1.00      0.80      0.89         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.75      2246\n","   macro avg       0.47      0.40      0.42      2246\n","weighted avg       0.74      0.75      0.74      2246\n","\n"]}]},{"cell_type":"code","source":["#보팅 \n","\n","voting_classifier = VotingClassifier(estimators=[\n","         ('lr', LogisticRegression(C=10000, penalty='l2')),\n","        ('cb', ComplementNB()),\n","        ('grbt', GradientBoostingClassifier(random_state=0))\n","], voting='soft', n_jobs=-1)\n","voting_classifier.fit(tfidfv, y_train)\n","\n","\n","print(classification_report(y_test,voting_classifier.predict(tfidfv_test), zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbhqBF-h5Rom","executionInfo":{"status":"ok","timestamp":1648648672798,"user_tz":-540,"elapsed":860090,"user":{"displayName":"강민호","userId":"16036611585333282679"}},"outputId":"226ce8ef-fe8d-4e11-e588-8b7792915558"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.58      0.70        12\n","           1       0.77      0.76      0.77       105\n","           2       0.76      0.65      0.70        20\n","           3       0.91      0.94      0.93       813\n","           4       0.78      0.86      0.82       474\n","           5       0.33      0.20      0.25         5\n","           6       0.93      1.00      0.97        14\n","           7       0.33      0.33      0.33         3\n","           8       0.62      0.63      0.62        38\n","           9       0.80      0.80      0.80        25\n","          10       0.86      0.83      0.85        30\n","          11       0.63      0.66      0.65        83\n","          12       0.43      0.46      0.44        13\n","          13       0.55      0.59      0.57        37\n","          14       0.20      0.50      0.29         2\n","          15       0.50      0.33      0.40         9\n","          16       0.69      0.74      0.71        99\n","          17       0.64      0.58      0.61        12\n","          18       0.65      0.55      0.59        20\n","          19       0.72      0.65      0.69       133\n","          20       0.59      0.49      0.53        70\n","          21       0.66      0.78      0.71        27\n","          22       0.00      0.00      0.00         7\n","          23       0.09      0.08      0.09        12\n","          24       0.69      0.47      0.56        19\n","          25       0.89      0.77      0.83        31\n","          26       0.75      0.38      0.50         8\n","          27       0.50      0.25      0.33         4\n","          28       0.14      0.10      0.12        10\n","          29       0.40      1.00      0.57         4\n","          30       0.50      0.33      0.40        12\n","          31       0.64      0.54      0.58        13\n","          32       1.00      0.50      0.67        10\n","          33       0.60      0.60      0.60         5\n","          34       0.75      0.43      0.55         7\n","          35       1.00      0.33      0.50         6\n","          36       0.43      0.55      0.48        11\n","          37       0.00      0.00      0.00         2\n","          38       0.00      0.00      0.00         3\n","          39       0.40      0.40      0.40         5\n","          40       0.67      0.20      0.31        10\n","          41       0.25      0.12      0.17         8\n","          42       0.00      0.00      0.00         3\n","          43       0.43      0.50      0.46         6\n","          44       1.00      0.80      0.89         5\n","          45       0.00      0.00      0.00         1\n","\n","    accuracy                           0.78      2246\n","   macro avg       0.55      0.48      0.50      2246\n","weighted avg       0.78      0.78      0.78      2246\n","\n"]}]}]}